<!DOCTYPE html>
<html lang="en-GB">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <title>I Tried Cursor and I'm Not Worried - Maikelology</title>
    <link rel="preload" href="/assets/css/main.css" as="style">
    <link rel="stylesheet" href="/assets/css/main.css" media="all">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>I Tried Cursor and I‚Äôm Not Worried | Maikelology</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="I Tried Cursor and I‚Äôm Not Worried" />
<meta name="author" content="Maikel Frias Mosquea" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I tested Cursor, for prototyping ideas to just figure if they are feasible it works, yet for production level it doesn‚Äôt. Context is their kryptonite. Our jobs are VERY MUCH safe." />
<meta property="og:description" content="I tested Cursor, for prototyping ideas to just figure if they are feasible it works, yet for production level it doesn‚Äôt. Context is their kryptonite. Our jobs are VERY MUCH safe." />
<link rel="canonical" href="https://blog.maikel.dev/2026/01/02/i-tried-cursor-and-im-not-worried.html" />
<meta property="og:url" content="https://blog.maikel.dev/2026/01/02/i-tried-cursor-and-im-not-worried.html" />
<meta property="og:site_name" content="Maikelology" />
<meta property="og:image" content="https://blog.maikel.dev/assets/images/unsplash-1571441249554.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-01-02T00:00:00+01:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://blog.maikel.dev/assets/images/unsplash-1571441249554.jpg" />
<meta property="twitter:title" content="I Tried Cursor and I‚Äôm Not Worried" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Maikel Frias Mosquea"},"dateModified":"2026-01-02T00:00:00+01:00","datePublished":"2026-01-02T00:00:00+01:00","description":"I tested Cursor, for prototyping ideas to just figure if they are feasible it works, yet for production level it doesn‚Äôt. Context is their kryptonite. Our jobs are VERY MUCH safe.","headline":"I Tried Cursor and I‚Äôm Not Worried","image":"https://blog.maikel.dev/assets/images/unsplash-1571441249554.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.maikel.dev/2026/01/02/i-tried-cursor-and-im-not-worried.html"},"url":"https://blog.maikel.dev/2026/01/02/i-tried-cursor-and-im-not-worried.html"}</script>
<!-- End Jekyll SEO tag -->

    <link type="application/atom+xml" rel="alternate" href="https://blog.maikel.dev/feed.xml" title="Maikelology" />
  </head>
  <body>
    <header class="site-header">
      <div class="wrapper">
        <nav class="site-nav">
          <a href="/">Home</a>
          <a href="/categories/">Categories</a>
          <a href="/about/">About</a>
        </nav>
        <a class="site-title" href="/">Maikelology</a>
        <a href="/search/" class="search-button" aria-label="Search">
          <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M9 17C13.4183 17 17 13.4183 17 9C17 4.58172 13.4183 1 9 1C4.58172 1 1 4.58172 1 9C1 13.4183 4.58172 17 9 17Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            <path d="M19 19L14.65 14.65" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          </svg>
        </a>
      </div>
    </header>

    <main class="page-content">
      <div class="wrapper">
        <article class="post">
  
  <div class="post-featured-image">
    <img src="/assets/images/unsplash-1571441249554.jpg" alt="I Tried Cursor and I'm Not Worried">
  </div>
  
  
  <header class="post-header">
    <h1 class="post-title">I Tried Cursor and I'm Not Worried</h1>
    
    <p class="post-excerpt">I tested Cursor, for prototyping ideas to just figure if they are feasible it works, yet for production level it doesn‚Äôt. Context is their kryptonite. Our jobs are VERY MUCH safe. </p>
    
    <div class="post-meta">
      <span class="post-author">Maikel Frias Mosquea</span>
      <span class="post-date">02 Jan 2026</span>
      
      
      
      
      <span class="post-reading-time">19 min read</span>
      
      
    </div>
  </header>

  <div class="post-content">
    <p>The image I‚Äôve chosen from Unsplash for this article is no accident at all, keep reading and you‚Äôll figure out why.</p>

<p>I recently survived showing someone <code class="language-plaintext highlighter-rouge">sparkr_private</code>, a repo containing a prototype version of <a href="https://codeberg.org/maikelthedev/sparkr">Sparkr</a> I built in React Native within a week. The goal wasn‚Äôt to build production code. It was to rapidly test <strong>feasibility</strong> of ideas, disposing of concepts quickly just to see what could actually be possible based on ideas in my head.</p>

<p>The result? Shameful code. Heavily written with the help of LLMs (specifically Cursor), it‚Äôs 100% slop built on top of slop, designed to answer one question after another:</p>

<ol>
  <li>Is this possible? Yes.</li>
  <li>Ok, is this possible? Yes, ok, next.</li>
  <li>Is this possible? Yes, ok, next.</li>
  <li>Is this possible? No? Ohhh, what if I do it this way? Yes, ok next.</li>
</ol>

<p>Rinse and repeat until I had all my questions answered.</p>

<p>The code <strong>individually</strong> worked, but integrated would probably make any mobile phone explode. There were no test suites, just monkey trialing after each idea. No integration tests. Once a feature was proved feasible I run the app on my phone, tested it manually, then I read the code to understand how, then I moved onto checking how the next one could be done. I guarantee you most new ideas broke the previous ones. I‚Äôm still debating with myself whether to make that code public.</p>

<p>But here‚Äôs the thing: it worked for its purpose. I learned that NIP-17 e2ee direct chat was possible (even if implemented in extremely wasteful and verbose ways) to add to a chatting app easily. I proved uploading facepics using free-to-use <a href="https://github.com/nostr-protocol/nips/blob/master/B7.md">Blossom relays </a>could work. I validated a grid <strong>directory</strong> system based on relays passed via app signature, posted in public relays.</p>

<p>From there onwards, I had all I needed to know it was feasible.</p>

<h2 id="the-only-valid-use-case">The Only Valid Use Case</h2>

<p>After this experiment, I‚Äôve found the only valid use case for LLMs in software development: testing feasibility of random ideas on disposable code to motivate yourself enough to code them yourself.</p>

<p><strong>Once you‚Äôve seen it, you want to make it real</strong>. You‚Äôre no longer working with an idea in your head. You answered each and every question you could have about it, to completion, and saw its full potential. It‚Äôs a bit like experiencing the joy of seeing your own children grow up and get married, knowing you made it happen, you raised a good kid, before actually deciding to have children. There‚Äôs no what if, there‚Äôs only a clear path. There‚Äôs no scrum or agile ever changing requirements, you‚Äôve gone from specification to final broken thing that kind of works. There‚Äôs no ifs, there‚Äôs no uncertainty. You‚Äôve seen it, had it in your hands, made of your ideas. Ignore the code, you just wanted to know if it could exist. You know now it can exist. It is <strong>a certainty</strong>.</p>

<p>Or, put another way: helping you gather answers to all the burning questions you might have on a software project before you write the first line of actual decent code.</p>

<p>This is genuinely useful. When you‚Äôre exploring a new domain, trying to understand if something is technically possible, or rapidly prototyping to validate concepts, discard what you figure doesn‚Äôt work and move onto quicker into alternative options.</p>

<p>But that‚Äôs where it ends.</p>

<h2 id="where-llms-fail-catastrophically">Where LLMs Fail Catastrophically</h2>

<p>If you‚Äôre thinking about using LLMs for actual software development, here‚Äôs where they IMHO fall apart:</p>

<h3 id="1-elegance">1. Elegance</h3>

<p>LLMs don‚Äôt understand elegance. They don‚Äôt grasp clean architecture, beautiful abstractions, or thoughtful design patterns. They‚Äôll give you code that works, but it‚Äôs the software equivalent of a functional but ugly building. It stands, but you wouldn‚Äôt want to live in it. Stupid ridiculous thing never had to pass an exam on algorithms, data structure or Big O notation, <a href="https://www.open.ac.uk/courses/modules/m269/"><strong>you did.</strong></a></p>

<p>They‚Äôll write stuff like this üëá</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">doStuff</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">,</span> <span class="nx">c</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if </span><span class="p">(</span><span class="nx">a</span> <span class="o">!=</span> <span class="kc">null</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">a</span> <span class="o">!==</span> <span class="kc">undefined</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">if </span><span class="p">(</span><span class="nx">a</span> <span class="o">!==</span> <span class="dl">""</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">b</span> <span class="o">==</span> <span class="kc">true</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">if </span><span class="p">(</span><span class="nx">c</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">doing stuff</span><span class="dl">"</span><span class="p">);</span>
            <span class="k">for </span><span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">c</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
              <span class="nf">setTimeout</span><span class="p">(</span><span class="nf">function </span><span class="p">()</span> <span class="p">{</span>
                <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="nx">a</span><span class="p">);</span>
              <span class="p">},</span> <span class="mi">1000</span><span class="p">);</span>
            <span class="p">}</span>
          <span class="p">}</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>
<p>There are some basic principles of software development that they simply ignore:</p>

<ul>
  <li>KISS, they write incredibly long lines of code with no specialisation or compartimentalisation in smaller functions, it‚Äôs untestable due to how long and how many variables it depends on .</li>
  <li>DRY, they write the same lines across entire codebases again and again.</li>
  <li>‚Ä¶.you can find the whole damn list here in Wikipedia. No one who‚Äôs studied software engineering would be unaware of the existence of those and many other rules.</li>
</ul>

<p>Anyone who‚Äôs coded for a couple of years can easily identify code written by a LLM compared to code written by a human.</p>

<h3 id="2-refactoring-and-global-view">2. Refactoring and Global View</h3>

<p>Ask an LLM to refactor code, and you‚Äôll get a mess. They don‚Äôt understand the subtle relationships between components, the reasons behind certain design decisions, or how to improve code while maintaining its integrity. They‚Äôll <strong>change things that shouldn‚Äôt be changed</strong> and <strong>leave problems that should be fixed.</strong></p>

<p>They‚Äôre terrible at handling project specific requirements, domain knowledge, or nuanced business logic. They‚Äôll give you generic solutions that don‚Äôt quite fit your actual needs. The devil is in the details, and LLMs are detail blind because they can‚Äôt see things <strong>globally</strong>. Why? Context. Remember, they aren‚Äôt human.</p>

<p>I‚Äôll talk more about this context thing later, but this is what makes them behave like elderly people with üëá and the main reason I‚Äôll never fear them.
<img src="https://images.unsplash.com/photo-1619963030941-69eb5b7ef496?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEzfHxhbHpoZWltZXJ8ZW58MHx8fHwxNzY3MzkxNTMzfDA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000" alt="white and yellow letter t" /></p>
<h3 id="3-testing">3. Testing</h3>

<p>Tests written by LLMs are <strong>awful</strong>. They test the wrong things, is not that they miss edge cases, but that they implementation details rather than behavior. Good testing requires understanding the system, its requirements, and potential failure modes, all things LLMs struggle with because of <strong>a lack of a global view.</strong> Context, my friend, that‚Äôs why you‚Äôll always have a job.</p>

<h3 id="4-anything-involving-refinement">4. Anything Involving Refinement</h3>

<p>LLMs are one-shot generators. They don‚Äôt iterate well. They don‚Äôt learn from feedback in a meaningful way. Real software development is iterative refinement, taking something that works and making it better, cleaner, more maintainable. LLMs can‚Äôt do this. You can tell them to rewrite the same function ten times and I gurantee you by the fourth time you‚Äôll get again the first version. Again, why? Repeat after me: <strong>context.</strong></p>

<h3 id="5-language-support-beyond-python-and-javascript">5. Language Support Beyond Python and JavaScript</h3>

<p>LLMs fail catastrophically at any language that‚Äôs not Python or JavaScript. In Elixir, for example, they even make up non-existent functions of core modules. They‚Äôll confidently suggest core-language functions that don‚Äôt exist, use incorrect syntax, and provide solutions that simply won‚Äôt compile or run. Let alone they are <strong>dated by design</strong>. Why do you think their best language for any of them to prototype with is JavaScript?</p>

<h2 id="the-junior-dev-fallacy">The ‚ÄúJunior Dev‚Äù Fallacy</h2>

<p>People who defend LLMs as if they were the 2nd cumming (typo intended) of Jesuschrist often say: ‚ÄúIt‚Äôs like sitting with a junior developer.‚Äù
<strong>No, it‚Äôs not.&lt;/blockquote&gt;
A junior developer **thinks</strong>. They ask questions. They learn. They make mistakes and understand why they made them. They <strong>grow their knowledge</strong>, they refine, they get better. They bring human judgment, <strong>creativity</strong>, and reasoning to the table.</p>

<p>An LLM vomits. It generates text based on patterns it‚Äôs seen, without understanding, without reasoning, without the ability to truly learn from <strong>context</strong> in the way a human does.</p>

<p>But here‚Äôs the critical difference that makes human coders irreplaceable:
<strong>context</strong>.&lt;/blockquote&gt;<img src="https://images.unsplash.com/photo-1762894764362-d264b9ffc92a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE0M3x8Y29udGV4dHxlbnwwfHx8fDE3NjczOTIzOTl8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000" alt="People waiting at a mural-adorned bus stop" /></p>
<h1 id="what-do-you-even-mean-with-context-maikel">What do you even mean with ‚Äúcontext‚Äù Maikel?</h1>

<p>A <strong>human</strong> developer can maintain a massively <strong>humongous</strong> context. They can hold in their head the entire architecture of a system, understand how components interact, remember why certain decisions were made months <strong>if not years</strong> ago, see the big picture and the small details simultaneously. They can trace through code mentally, understand the flow of data, see relationships that aren‚Äôt explicitly documented, and make connections across the entire codebase. They have <strong>a global vision.</strong></p>

<p>I have ADHD yet unlike most, when I‚Äôm unmedicated, my working memory is so large I can hold in my head the entire architecture of an idea for weeks if not months. I can think through complex systems, see how everything connects, and maintain that mental model continuously while I try pseudocode in my head.<strong>An LLM can‚Äôt do more than a few prompts without forgetting the entire subject.</strong> Even the most advanced models with massive context windows can‚Äôt maintain that kind of persistent, deep understanding. They reset. They forget. They can‚Äôt hold onto the architecture the way a human mind can.</p>
<div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">üí°</div><div class="kg-callout-text">**Context: T**here's a very tiny window of information you can supply to them, past this window they start from scratch as if an elderly person with dementia.</div></div>
<p>That‚Äôs what **context **means for an LLM. he bigger the context size, the slower they get and they **all **have this limitation. They‚Äôll never get global-type of understanding to any codebase unless it is so tiny it fits entirely in their context, together with the much larger amount of reasoning of what it does, why it does it, etc.</p>

<p>Any LLM, even with the largest context windows available, fails precisely where humans excel. Context windows are limited. They can‚Äôt truly ‚Äúremember‚Äù beyond what‚Äôs in the current conversation. They can‚Äôt maintain the kind of deep, interconnected understanding that a human developer builds over time working with a codebase. They process text, not meaning. They see tokens, not systems.</p>

<p>This is where human coders will always prevail. Real software development isn‚Äôt about writing isolated functions. It‚Äôs about understanding complex systems, maintaining mental models of how everything fits together, and making decisions that consider the entire context of the project, its history, its future, and its constraints. LLMs can‚Äôt do this. They can only work with what‚Äôs explicitly in their context window, and even then, they don‚Äôt truly understand it.
<strong>Moral of the story:</strong> you cannot write professional code with an LLM. You can use it to test the feasibility of some ideas and that‚Äôs it.&lt;/blockquote&gt;</p>
<h2 id="the-professionals-approach-that-imho-should-be-the-gold-standard-on-llm-usage">The Professional‚Äôs Approach that IMHO should be the gold-standard on LLM usage</h2>

<p>So how do you use LLMs without destroying your career or your codebase?</p>

<p>First, <strong>assume their knowledge is based on inaccuracies</strong>. Don‚Äôt ask them if something is feasible. Direct them to code your idea, so you can see with your own eyes if it is and fix what it gets wrong.<strong>Never use LLMs as juries of what is possible</strong>. Never take their opinion. They aren‚Äôt people, <strong>they are all snake oil salesmen.</strong> Their job is to sound knowledgeable, not to produce actual knowledge. Do you think the guy at MediaMarkt has any clue of the actual power of an i7-13123 vs an AMD Ryzen 7 Gen 8 v2.5 (I just made up tha last part)? His job is neither to draw sillicon logic in ever shrinking transistor size, with an ever increasing set of instructions to process things ever quicker, using ever more complicated manufacturing processses. Nope, that‚Äôs not his job, his job is to sell.</p>

<p>So instead focus on making them do quickly the prototypes of ideas you had in your head. Think of it as a feedback loop overcharged of the ideas that you will ask yourself over a number of weeks, in just days or 24 hours. But ultimately the machine would answer them a lot quicker, just a lot less accurately and more constrained. The prototype you end up with is just one of hundreds of millions of possibilities. <strong>The box cannot think outside the box.</strong> YOU CAN.</p>

<h3 id="1-use-a-different-language-for-prototyping-one-you-dont-care-much-about">1. Use a Different Language for Prototyping one you don‚Äôt care much about</h3>

<p>Never use an LLM for the final programming language you‚Äôre going to use. Only use it for with shite error-ignoring-prone languages that you don‚Äôt get paid professionally to use anymore, like JavaScript (if that‚Äôs not your main language).</p>

<p>Why? This ensures your knowledge of your food-on-the-table language remains intact due to constant use <strong>unaided</strong>. It also avoids future <strong>licensing</strong> issues. Most importantly, it makes copy and paste between prototype and final product impossible.</p>

<p>So prototype ideas on a shite language, write them yourself on the proper one.
<img src="https://images.unsplash.com/photo-1692734207733-a79de344ff3a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQ2fHxzaGl0fGVufDB8fHx8MTc2NzM5MzU5M3ww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000" alt="a red sign with a picture of a cow on it" /></p>
<h3 id="2-never-use-it-with-your-professional-language-or-the-one-you-feel-passionate-about">2. Never Use It With Your Professional Language or the one you feel passionate about</h3>

<p>If JavaScript is your professional language, use Python for prototyping. The separation is crucial.</p>

<p>Here‚Äôs my personal approach: JavaScript was my professional language for quite a while. I can still read it and code in React, Angular, React Native, or NativeScript when designing quick prototypes for Android, Angular was paying the bills. But I haven‚Äôt used it professionally in a very long time, nor do I think I will. My main **decent **languages that I get paid sustenance money for are Elixir, which I deeply love, and hopefully soon Kotlin, which finally covers the problems of Java‚Äôs obsessive OOP, and finally able to do what React Native had for me: multiplatform, thanks to Kotlin Multiplatform.</p>

<p><strong>I need to know what I‚Äôm doing with these languages,</strong> so no LLMs with them. Even better if you can use pseudocode for prototyping. Pseudocode lets you think through the logic and architecture without committing to any specific language, and then you can implement it properly in your professional language yourself. This maintains your skills while still allowing you to rapidly prototype ideas.</p>

<p>We need to compartmentalize: code we write from code LLMs produce. The best way is to use it to understand a concept, read through it, close the fucking tool, and force yourself to write from scratch the code yourself in that different language. As I said before: test the feasibility of ideas, never their actual implementation.</p>

<p>The main reason is the one I mentioned earlier, licensing issues. Imagine you work on a project, you worked aided by some LLM and then months down the line you discover your code comes (inevitably) from copyrighted code with an incompatible viral license to what you‚Äôve ‚Äúwritten‚Äù for someone else. I‚Äôm not talking about some for loop, I‚Äôm talking about those <strong>naive</strong> fake-fluencers trying to sell you books, seminars, and other bullshit, about completely code-free coding using agentic-mode only. There‚Äôs no way they aren‚Äôt ending up with large sections of ‚Äútheir‚Äù code being copyright-breaking material with lawyers in-waiting. This is going to probably end up being so big, these kinds of ads will have to be created with different banner ‚Äú<strong>has your code being used in a large codebase elsewhere, no win, no fee</strong>‚Äù.
<img src="/assets/images/2026-01-image-1.png" alt="Image" /></p>
<h3 id="3-use-local-models-when-possible">3. Use Local Models When Possible</h3>

<p>Swap for local models with tools like Ollama as soon as you can. But be VERY aware: they are a black box. Every line of code out of an LLM is code stolen from somewhere and that somewhere clearly has a license just as much as anything sucked by a commercial-provider. NEVER copy and paste.</p>

<p>Even with local models, you‚Äôre dealing with code that was trained on, <strong>always assume, copyrighted materia</strong>l. The licensing implications are enough to remember you cannot and should not use their code.</p>

<p>The local models have a big advantage: nothing leaves your PC. The code you write, using a commercial LLM, always end up on someone else‚Äôs server. Cursor has a setting to keep thinks locally, I assume that setting is misleading.<strong>Never put the code you write for one of your clients on LLMs but specially online ones.</strong> Assume the company behind it is harvesting your prompts for further refinement of the model, and that everything you enter on it, will be used by someone else later. You might be digging your grave.</p>

<h3 id="4-never-invest-in-this-tech">4. Never Invest in This Tech</h3>

<p>Don‚Äôt buy GPUs to use them locally, don‚Äôt get the greatest 64 GB Apple Sillicon laptop to try different models locally, unless you have the spare funds. Assume it‚Äôll vanish into thin air. Don‚Äôt put your value on requiring them. Never develop dependency on them.</p>

<p>Nothing depreciates faster than software, and this is clearly an unsustainable bubble on snakeoil sales-speech software.</p>

<p>You‚Äôve lived through Uber, Airbnb, and other venture capitalistic cunts. You know what OpenAI and others will do. This shit is cheap now, <strong>it‚Äôll cost 10 times more in the near future</strong>. They are burning through VC cash to get you hooked into it. Same as Uber did while destroying their local taxi competitors, and now they are pricier than local taxis. Same as Starbucks does opening multiple stores to asphyxiate the competitors. It‚Äôs all the same strategy: cheap now, gets you hooked, become a commodity, then raise the prices.</p>

<p>Don‚Äôt build your career or your projects on something that will become unaffordable once they‚Äôve eliminated the competition and you‚Äôre locked in.</p>

<p>The LocalLLM market is entirely different, and for certain do investigate on it for fun as much as you‚Äôd like as I think this sub-are of LLMs is what will eventually rise victorious.</p>

<h3 id="5-maintain-self-control">5. Maintain Self-Control</h3>

<p>All of this requires self control. How much of an adult are you? How much do you value your employability?</p>

<p>The temptation to use LLMs for ‚Äúreal‚Äù work is strong. Short term might feel like you can do one week‚Äôs worth of work in an couple of hours. But in the long term, it erodes your skills, creates technical debt, produces code that‚Äôs harder to maintain, and makes you dependent on a service that will become eventually either unaffordable to you or unusable due to licensing issues.</p>

<p>Think about this: if running a local LLM that produces anything near the quality of Cursor‚Äôs default model costs you a humongous debt in computer components, what incentive do the already existing commercial ones have to NOT eventually raise what they charge for it. They aren‚Äôt NGOs, they are all for-profit companies.</p>

<p>It‚Äôs a fad, it‚Äôll go and evolve into mini-local LLM models.</p>

<h2 id="conclussion-why-the-rubbish-image-and-why-our-future-is-safe">Conclussion, why the rubbish image and why our Future is Safe</h2>

<p>I don‚Äôt think professional software development is going anywhere in favour of machines doing it.</p>

<p>The people who will ignore this advice? Clearly those who don‚Äôt work professionally as coders. Professional developers understand that code isn‚Äôt just about making something work, it‚Äôs about making something work well, maintainably, and elegantly. It‚Äôs like raising a kid.</p>

<p>But I don‚Äôt think we‚Äôre through the worse yet. I think first, will come the commodifying of LLMs, getting as many people hooked as possible, second the hiking of the prices, third, the selling of the convenience of commercial ones compared to local LLMs, then legislation will FINALLY catch up (if ever) and burst the bubble of the commercial ones (that‚Äôs where the injury-lawyer industry re-focus will happen into <strong>some major copyright battles</strong>), then some local LLMs will become easier to understand and run, then there‚Äôll be probably more openness (enforced by the law, probably the EU first) about the source of LLMs ‚Äúknowledge‚Äù and finally purpose-built per coding-language and ecosystem language models. Tiny thematicals LLMs capable of requiring less power since they are focused on a single thematic task (like, future Jetpack Compose UI generators).</p>

<p>I‚Äôm expecting the bubbele to burst spectacularly and in a similar way the housing crash did since we‚Äôre humans, which means, our context window is neither infinite and love repeating our own mistakes. Every bank surely has directly or indirectly invested in this crap, and the moment OpenAI crash we‚Äôll have another Lehman Brothers moment
**OpenAI is the new Lehman Brothers &lt;/blockquote&gt;
Now, why that image? Because when I think of Sillicon Valley and Big Tech‚Ñ¢Ô∏è, that‚Äôs what comes to my mind: rubbish and people going through it, trying to find value. Yet instead of looking in the recyclable bin, where by definition it is easier to find something that worked in the past and refine it, they look into the non-recyclable one, the one filled with dog poo and cat litter, and try to sell it to us as The Cum of Christ, Microsoft is particularly guilty of this, no matter how many times people shout at them ‚ÄúI don‚Äôt want to eat a used diaper‚Äù they persistently repeat ‚Äúnow with Premium Poo‚Äùüëá</p>

<center><strong>No, thank you.</strong></center>

<p>LLMs are a tool. Like any tool, they‚Äôre useful for specific tasks and terrible for others. Use them for what they‚Äôre good at: rapid feasibility testing on disposable code. Don‚Äôt use them for what they‚Äôre bad at: actual software development.</p>

<p>Our future is safe because professional software development requires skills that LLMs simply won‚Äôt ever have due to their main limitation: context.</p>

<p>The developers who will thrive are the ones who understand this distinction and maintain their skills accordingly. The ones that will have to re-skill themselves into some other industry are those who fell for the vibe-coding fad.</p>

<p>Thanks for coming to my house, tip your waitress. Byyeeeee!</p>
<figure><iframe src="https://tenor.com/embed/5266957" frameborder="0"></iframe></figure>

  </div>
</article>


      </div>
    </main>

    <footer class="site-footer">
      <div class="wrapper">
        <p>&copy; 2026 Maikelology. All rights reserved.</p>
      </div>
    </footer>
    
    <script>
      // Add anchor links to all headers
      // Use requestAnimationFrame to ensure layout is stable after CSS loads
      function initAnchors() {
        const headers = document.querySelectorAll('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]');
        
        headers.forEach(function(header) {
          // Check if anchor link already exists
          if (header.querySelector('a.anchor')) {
            return;
          }
          
          const id = header.getAttribute('id');
          if (!id) return;
          
          const anchor = document.createElement('a');
          anchor.href = '#' + id;
          anchor.className = 'anchor';
          anchor.textContent = '#';
          anchor.setAttribute('aria-label', 'Link to this section');
          
          header.insertBefore(anchor, header.firstChild);
        });
      }
      
      // Wait for DOM and ensure layout is stable
      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', function() {
          requestAnimationFrame(function() {
            requestAnimationFrame(initAnchors);
          });
        });
      } else {
        requestAnimationFrame(function() {
          requestAnimationFrame(initAnchors);
        });
      }
    </script>
  </body>
</html>
